import streamlit as st
import google.generativeai as genai
from PIL import Image
import io
import base64
from datetime import datetime
import tiktoken
import json
import time
import re

# Cáº¥u hÃ¬nh trang
st.set_page_config(page_title="TrÃ² chuyá»‡n Äa phÆ°Æ¡ng tiá»‡n vá»›i Gemini", layout="wide", page_icon="ğŸš€")

# Khá»Ÿi táº¡o tráº¡ng thÃ¡i phiÃªn
if "messages" not in st.session_state:
    st.session_state.messages = []
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "image" not in st.session_state:
    st.session_state.image = None
if "model_config" not in st.session_state:
    st.session_state.model_config = {
        "model_name": "gemini-1.5-flash-latest",
        "temperature": 0.7,
        "top_p": 1.0,
        "top_k": 40,
        "max_output_tokens": 2048,
    }
if "system_prompt" not in st.session_state:
    st.session_state.system_prompt = "Báº¡n lÃ  má»™t trá»£ lÃ½ AI há»¯u Ã­ch vÃ  thÃ¢n thiá»‡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi tanbaycu. "
if "total_tokens" not in st.session_state:
    st.session_state.total_tokens = 0
if "theme" not in st.session_state:
    st.session_state.theme = "light"
if "font_size" not in st.session_state:
    st.session_state.font_size = "medium"

GEMINI_MODELS = [
    "gemini-1.5-flash-latest",
    "gemini-2.0-flash-exp",
    "gemini-1.5-flash-8b",
    "gemini-2.0-pro-exp-02-05",
    "gemini-2.0-flash-lite-preview-02-05"
]

MAX_TOKENS = 8192  # Giáº£ sá»­ Ä‘Ã¢y lÃ  giá»›i háº¡n token cho mÃ´ hÃ¬nh

# CSS tÃ¹y chá»‰nh
def get_custom_css():
    return f"""
<style>
    .stButton > button {{width: 100%;}}
    .stTextInput > div > div > input {{background-color: {'#f0f2f6' if st.session_state.theme == 'light' else '#2b313e'};}}
    .sidebar .stButton > button {{background-color: #4CAF50; color: white;}}
    .sidebar .stButton > button:hover {{background-color: #45a049;}}
    .chat-message {{
        padding: 1rem; 
        border-radius: 0.5rem; 
        margin-bottom: 1rem; 
        display: flex;
        font-size: {{'0.8rem' if st.session_state.font_size == 'small' else '1rem' if st.session_state.font_size == 'medium' else '1.2rem'}};
        animation: fadeIn 0.5s;
    }}
    @keyframes fadeIn {{
        0% {{ opacity: 0; }}
        100% {{ opacity: 1; }}
    }}
    .chat-message.user {{background-color: {'#e6f3ff' if st.session_state.theme == 'light' else '#2b313e'};}}
    .chat-message.bot {{background-color: {'#f0f0f0' if st.session_state.theme == 'light' else '#3c4354'};}}
    .chat-message .avatar {{width: 15%; padding-right: 0.5rem;}}
    .chat-message .avatar img {{max-width: 40px; max-height: 40px; border-radius: 50%;}}
    .chat-message .message {{width: 85%; padding: 0 1.5rem;}}
    .chat-message .timestamp {{font-size: 0.8em; color: {'#a0a0a0' if st.session_state.theme == 'light' else '#cccccc'}; text-align: right; margin-top: 0.5rem;}}
    .token-info {{font-size: 0.8em; color: {'#a0a0a0' if st.session_state.theme == 'light' else '#cccccc'}; margin-top: 0.5rem;}}
    body {{background-color: {'#ffffff' if st.session_state.theme == 'light' else '#1e1e1e'}; color: {'#000000' if st.session_state.theme == 'light' else '#ffffff'};}}
    .stAlert {{animation: slideIn 0.5s;}}
    @keyframes slideIn {{
        0% {{ transform: translateY(-100%); }}
        100% {{ transform: translateY(0); }}
    }}
</style>
"""

st.markdown(get_custom_css(), unsafe_allow_html=True)

# CÃ¡c hÃ m tiá»‡n Ã­ch
@st.cache_resource
def load_model(api_key, model_name):
    try:
        genai.configure(api_key=api_key)
        return genai.GenerativeModel(model_name=model_name)
    except Exception as e:
        st.error(f"Lá»—i khá»Ÿi táº¡o mÃ´ hÃ¬nh: {str(e)}")
        return None

@st.cache_data
def get_image_download_link(_img, filename, text):
    buffered = io.BytesIO()
    _img.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    href = f'<a href="data:file/png;base64,{img_str}" download="{filename}">{text}</a>'
    return href

def get_chat_history():
    return "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.chat_history[-st.session_state.max_history:]])

@st.cache_data
def count_tokens(text):
    encoding = tiktoken.get_encoding("cl100k_base")
    return len(encoding.encode(text))

# ThÃªm hÃ m má»›i Ä‘á»ƒ xá»­ lÃ½ giá»›i háº¡n tá»‘c Ä‘á»™
def rate_limited_response(func):
    def wrapper(*args, **kwargs):
        if 'last_request_time' not in st.session_state:
            st.session_state.last_request_time = 0
        
        current_time = time.time()
        time_since_last_request = current_time - st.session_state.last_request_time
        
        if time_since_last_request < 1:  # Giá»›i háº¡n 1 yÃªu cáº§u má»—i giÃ¢y
            time.sleep(1 - time_since_last_request)
        
        result = func(*args, **kwargs)
        st.session_state.last_request_time = time.time()
        return result
    return wrapper

@rate_limited_response
def handle_user_input(user_input, model):
    sanitized_input = sanitize_input(user_input)
    chat_history = get_chat_history()
    full_prompt = f"{st.session_state.system_prompt}\n\nLá»‹ch sá»­ trÃ² chuyá»‡n:\n{chat_history}\n\nNgÆ°á»i dÃ¹ng: {sanitized_input}\n\nTrá»£ lÃ½:"
    
    inputs = [full_prompt]
    if st.session_state.image:
        inputs.append(st.session_state.image)
    
    try:
        with st.spinner('ğŸ¤” Äang táº¡o pháº£n há»“i...'):
            response = model.generate_content(
                inputs,
                generation_config=genai.types.GenerationConfig(
                    temperature=st.session_state.model_config["temperature"],
                    top_p=st.session_state.model_config["top_p"],
                    top_k=st.session_state.model_config["top_k"],
                    max_output_tokens=st.session_state.model_config["max_output_tokens"],
                )
            )
        response_tokens = count_tokens(response.text)
        st.session_state.total_tokens += response_tokens
        return response.text, response_tokens
    except Exception as e:
        st.error(f"Lá»—i táº¡o pháº£n há»“i: {str(e)}")
        return None, 0

def sanitize_input(text):
    # Loáº¡i bá» cÃ¡c tháº» HTML
    text = re.sub('<[^<]+?>', '', text)
    # Escape cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t
    text = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;').replace('"', '&quot;').replace("'", '&#39;')
    return text

def save_chat_session():
    session_data = {
        "messages": st.session_state.messages,
        "chat_history": st.session_state.chat_history,
        "total_tokens": st.session_state.total_tokens
    }
    return json.dumps(session_data)

def load_chat_session(session_data):
    data = json.loads(session_data)
    st.session_state.messages = data["messages"]
    st.session_state.chat_history = data["chat_history"]
    st.session_state.total_tokens = data["total_tokens"]

def is_valid_api_key(api_key):
    # ÄÃ¢y lÃ  kiá»ƒm tra cÆ¡ báº£n. Báº¡n cÃ³ thá»ƒ muá»‘n triá»ƒn khai má»™t xÃ¡c thá»±c máº¡nh máº½ hÆ¡n.
    return bool(api_key) and len(api_key) > 10

# Thanh bÃªn
with st.sidebar:
    st.title("CÃ i Ä‘áº·t")
    
    if 'api_key' not in st.session_state:
        st.session_state.api_key = ''
    api_key = st.text_input("Nháº­p Google API Key", type="password", value=st.session_state.api_key)
    
    with st.expander("ğŸ› ï¸ TÃ¹y chá»‰nh MÃ´ hÃ¬nh", expanded=False):
        selected_model = st.selectbox("Chá»n mÃ´ hÃ¬nh Gemini", GEMINI_MODELS, index=GEMINI_MODELS.index(st.session_state.model_config["model_name"]))
        st.session_state.model_config["model_name"] = selected_model
        
        st.session_state.model_config["temperature"] = st.slider("ğŸŒ¡ï¸ Äá»™ sÃ¡ng táº¡o", min_value=0.0, max_value=1.0, value=st.session_state.model_config["temperature"], step=0.1)
        st.session_state.model_config["top_p"] = st.slider("ğŸ¯ Top P", min_value=0.0, max_value=1.0, value=st.session_state.model_config["top_p"], step=0.1)
        st.session_state.model_config["top_k"] = st.number_input("ğŸ” Top K", min_value=1, max_value=100, value=st.session_state.model_config["top_k"])
        st.session_state.model_config["max_output_tokens"] = st.number_input("ğŸ“ Sá»‘ token tá»‘i Ä‘a", min_value=1, max_value=8192, value=st.session_state.model_config["max_output_tokens"])
    
    with st.expander("ğŸ“ TÃ¹y chá»‰nh Prompt", expanded=False):
        st.session_state.system_prompt = st.text_area("System Prompt", value=st.session_state.system_prompt, height=100)
    
    st.session_state.max_history = st.slider("ğŸ§  Sá»‘ lÆ°á»£ng tin nháº¯n tá»‘i Ä‘a trong lá»‹ch sá»­", min_value=1, max_value=20, value=5)
    
    uploaded_file = st.file_uploader("ğŸ“¸ Táº£i lÃªn má»™t hÃ¬nh áº£nh...", type=["jpg", "jpeg", "png"])

    if uploaded_file:
        st.session_state.image = Image.open(uploaded_file)
        st.image(st.session_state.image, caption='HÃ¬nh áº£nh Ä‘Ã£ táº£i lÃªn', use_column_width=True)
        st.markdown(get_image_download_link(st.session_state.image, "hÃ¬nh_áº£nh_Ä‘Ã£_táº£i.png", "ğŸ“¥ Táº£i xuá»‘ng hÃ¬nh áº£nh"), unsafe_allow_html=True)

    # Menu hamburger cho cÃ¡c tÃ¹y chá»n bá»• sung
    with st.expander("â˜° TÃ¹y chá»n nÃ¢ng cao", expanded=False):
        st.subheader("Quáº£n lÃ½ phiÃªn trÃ² chuyá»‡n")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ XÃ³a", key="clear_history"):
                st.session_state.messages = []
                st.session_state.chat_history = []
                st.session_state.image = None
                st.session_state.total_tokens = 0
                st.rerun()

        with col2:
            if st.button("ğŸ“¥ Xuáº¥t", key="export_history"):
                chat_history = "\n".join([f"{msg['role']} ({msg.get('timestamp', 'N/A')}): {msg['content']}" for msg in st.session_state.chat_history])
                st.download_button(
                    label="ğŸ“¥ Táº£i xuá»‘ng",
                    data=chat_history,
                    file_name="lich_su_tro_chuyen.txt",
                    mime="text/plain"
                )
        
        st.subheader("LÆ°u vÃ  táº£i phiÃªn trÃ² chuyá»‡n")
        if st.button("ğŸ’¾ LÆ°u"):
            session_data = save_chat_session()
            st.download_button(
                label="ğŸ“¥ Táº£i xuá»‘ng phiÃªn trÃ² chuyá»‡n",
                data=session_data,
                file_name="phien_tro_chuyen.json",
                mime="application/json"
            )
        
        uploaded_session = st.file_uploader("ğŸ“¤ Táº£i lÃªn", type=["json"])
        if uploaded_session is not None:
            session_data = uploaded_session.getvalue().decode("utf-8")
            load_chat_session(session_data)
            st.success("ÄÃ£ táº£i phiÃªn trÃ² chuyá»‡n thÃ nh cÃ´ng!")

        st.subheader("ThÃ´ng tin MÃ´ hÃ¬nh")
        st.info(f"""
        - ğŸ¤– MÃ´ hÃ¬nh: {st.session_state.model_config['model_name']}
        - ğŸŒ¡ï¸ Äá»™ sÃ¡ng táº¡o: {st.session_state.model_config['temperature']:.2f}
        - ğŸ¯ Top P: {st.session_state.model_config['top_p']:.2f}
        - ğŸ” Top K: {st.session_state.model_config['top_k']}
        - ğŸ“ Sá»‘ token tá»‘i Ä‘a: {st.session_state.model_config['max_output_tokens']}
        - ğŸ§  Sá»‘ lÆ°á»£ng tin nháº¯n trong lá»‹ch sá»­: {st.session_state.max_history}
        - ğŸ’¬ Tá»•ng sá»‘ tin nháº¯n: {len(st.session_state.messages)}
        - ğŸ”¢ Tá»•ng sá»‘ token: {st.session_state.total_tokens}
        """)

        # Thanh tiáº¿n trÃ¬nh token
        st.subheader("Sá»­ dá»¥ng Token")
        progress = st.session_state.total_tokens / MAX_TOKENS
        st.progress(progress)
        st.text(f"{st.session_state.total_tokens}/{MAX_TOKENS} tokens Ä‘Ã£ sá»­ dá»¥ng")

# Ná»™i dung chÃ­nh
st.title("ğŸš€ Gemini Agent")
st.caption("Tráº£i nghiá»‡m sá»©c máº¡nh cá»§a cÃ¡c mÃ´ hÃ¬nh Gemini má»›i nháº¥t vá»›i tÃ¹y chá»‰nh nÃ¢ng cao. ğŸŒŸ")

if api_key:
    if is_valid_api_key(api_key):
        st.session_state.api_key = api_key
        model = load_model(api_key, st.session_state.model_config["model_name"])
        
        if model:
            # Hiá»ƒn thá»‹ lá»‹ch sá»­ trÃ² chuyá»‡n
            for msg in st.session_state.chat_history:
                with st.chat_message(msg["role"]):
                    st.markdown(msg["content"])
                    timestamp = msg.get('timestamp', 'N/A')
                    tokens = msg.get('tokens', 'N/A')
                    st.markdown(f"<div class='timestamp'>{timestamp} | Tokens: {tokens}</div>", unsafe_allow_html=True)

            # Xá»­ lÃ½ input cá»§a ngÆ°á»i dÃ¹ng
            prompt = st.chat_input("ğŸ’¬ Báº¡n muá»‘n biáº¿t gÃ¬?")
            if prompt:
                with st.chat_message("user"):
                    st.markdown(sanitize_input(prompt))
                    tokens = count_tokens(prompt)
                    timestamp = datetime.now().strftime("%H:%M:%S")
                    st.markdown(f"<div class='timestamp'>{timestamp} | Tokens: {tokens}</div>", unsafe_allow_html=True)
                    st.session_state.total_tokens += tokens
                    st.session_state.chat_history.append({
                        "role": "user",
                        "content": sanitize_input(prompt),
                        "tokens": tokens,
                        "timestamp": timestamp
                    })

                with st.chat_message("assistant"):
                    response, response_tokens = handle_user_input(prompt, model)
                    if response:
                        st.markdown(response)
                        timestamp = datetime.now().strftime("%H:%M:%S")
                        st.markdown(f"<div class='timestamp'>{timestamp} | Tokens: {response_tokens}</div>", unsafe_allow_html=True)
                        st.session_state.chat_history.append({
                            "role": "assistant",
                            "content": response,
                            "tokens": response_tokens,
                            "timestamp": timestamp
                        })

            # Cáº£nh bÃ¡o náº¿u cÃ³ hÃ¬nh áº£nh nhÆ°ng khÃ´ng cÃ³ prompt
            if st.session_state.image and not prompt:
                st.warning("âš ï¸ Vui lÃ²ng nháº­p cÃ¢u há»i Ä‘á»ƒ Ä‘i kÃ¨m vá»›i hÃ¬nh áº£nh.")
        else:
            st.error("âŒ KhÃ´ng thá»ƒ khá»Ÿi táº¡o mÃ´ hÃ¬nh. Vui lÃ²ng kiá»ƒm tra API key vÃ  thá»­ láº¡i.")
    else:
        st.error("âŒ API key khÃ´ng há»£p lá»‡. Vui lÃ²ng nháº­p má»™t Google API Key há»£p lá»‡.")
else:
    st.warning("ğŸ”‘ Vui lÃ²ng nháº­p Google API Key cá»§a báº¡n á»Ÿ thanh bÃªn Ä‘á»ƒ báº¯t Ä‘áº§u trÃ² chuyá»‡n.")

# Footer
st.markdown("---")
st.markdown("ÄÆ°á»£c phÃ¡t triá»ƒn vá»›i â¤ï¸ bá»Ÿi tanbaycu")

